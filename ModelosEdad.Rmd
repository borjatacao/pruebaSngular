---
title: "Modelos para la predicción de la Edad como un problema de regresión"
output:
  html_document: 
    toc: true
    toc_depth: 2
    number_sections: true
    code_folding: hide
    toc_float:
      collapsed: false
editor_options:
  chunk_output_type: inline
---

```{r results='hide', message=FALSE, warning=FALSE}
# Librerías utilizadas en este notebook
# Las instalo si es necesario. De lo contrario sólo las cargo
for (package in c('ggplot2', 'reshape2', 'glmnet', 'knitr', 'GGally','rockchalk', 'MASS', 'caret', 'pls', 'tree', 'randomForest', 'gbm', 'sigmoid')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}

# Fijar la semilla para reproducir los métodos aleatorios
set.seed(1)

```

```{r results='hide', message=FALSE, warning=FALSE}
 calculateRMSE = function(yhat, y){
  return( mean((yhat - y)^2) )
 }

calculateaAccuracy = function(yhat, y){
  return( sum(abs(yhat - y) <= 0.5 ) / length(yhat) * 100)
 }

calculateAdjR2 = function(yhat, y, nVar){
  return( 1 - calculateRMSE(yhat, y) / mean((y - mean(y))^2) * 
              (length(y) - 1) / (length(y) - nVar - 1) )
}

calculateResults = function(yhat, y, train, test, modelName, nVar){
  if(missing(nVar)){
    R2Test = NA
    R2Train = NA
  }
  else{
    R2Train = calculateAdjR2(yhat[train], y[train], nVar)
    R2Test  = calculateAdjR2(yhat[test], y[test], nVar)
  }
  ret = data.frame( "Modelo"  = modelName,
                "Acc Entr" = calculateaAccuracy(yhat[train], y[train]),
                "Acc Test" = calculateaAccuracy(yhat[test], y[test]),
                "ECM Entr"= calculateRMSE(yhat[train], y[train]),
                "ECM Test"= calculateRMSE(yhat[test], y[test]) ,
                "R2 adj Entr"= R2Train,
                "R2 adj Test"= R2Test
                )
  return ( ret )
  
}

showResults = function (results){
    kable(results[order(results$ECM.Test),], digits = 4,format = 'markdown', row.names = FALSE)
}

getBestResult = function(fitCaret) {
  best = which(rownames(fitCaret$results) == rownames(fitCaret$bestTune))
  bestResult = fitCaret$results[best, ]
  rownames(bestResult) = NULL
  return (bestResult)
}

plotModel = function(model){
  par(mfrow = c(2, 2))
  plot(model)
  par(mfrow = c(1,1))
}


```

# Generación de nuevas variables para reducir la colinealidad
Como hemos analizado durante el [análisis exploratorio](./AnalisisExploratorio.html) de Abalone, las variables independientes están muy relacionadas entre sí. Vamos a tratar de crear nuevas variables que resuman el contenido de las demás. De esta forma, podemos reducir las dimensiones de nuestros modelos mientras mantenemos la mayor cantidad de información posible.

```{r}
load("abaloneCorregido.Rdata")
```


## Nuevas variables dependientes del peso
```{r}
abaloneNewFeat = abaloneClean
abaloneNewFeat$WeightGeoMean = (abaloneClean$WholeWeight * abaloneClean$ShuckedWeight * abaloneClean$VisceraWeight * abaloneClean$ShellWeight)^(1/4)

abaloneNewFeat$WeightNorm = sqrt(abaloneClean$WholeWeight^2 + abaloneClean$ShuckedWeight^2 + abaloneClean$VisceraWeight^2 + abaloneClean$ShellWeight^2)

p=ggplot(melt(abaloneNewFeat[,(ncol(abaloneNewFeat)-1):ncol(abaloneNewFeat)]),aes(x = value), fill=variable) + geom_boxplot(aes(x = variable, y = value, color=variable)) + guides(colour=FALSE)

p + theme(axis.title.x = element_blank()) + ylab("Nuevas variables de peso")

```

## Nuevas variables dependientes de variables espaciales
```{r}
abaloneNewFeat$Volume = (abaloneClean$Length * abaloneClean$Diameter * abaloneClean$Height)

abaloneNewFeat$SizeGeoMean = (abaloneClean$Length * abaloneClean$Diameter * abaloneClean$Height)^(1/3)

abaloneNewFeat$SizeGeoNorm = sqrt(abaloneClean$Length^2 + abaloneClean$Diameter^2 + abaloneClean$Height^2 )

summary (abaloneNewFeat[, (ncol(abaloneNewFeat)-2):ncol(abaloneNewFeat)])

scaledAbalone = stack(as.data.frame(scale(abaloneNewFeat[, (ncol(abaloneNewFeat)-2):ncol(abaloneNewFeat)])))

p =ggplot(scaledAbalone) + geom_boxplot(aes(x = ind, y = values, color=ind)) + guides(colour=FALSE)

p + theme(axis.title.x = element_blank()) + ylab("Nuevas variables espaciales")

```

## Nuevas variables dependientes del peso y el volumen
```{r}
abaloneNewFeat$Density = abaloneClean$WholeWeight/(abaloneClean$Length * abaloneClean$Diameter * abaloneClean$Height)

abaloneNewFeat$DensityShucked = abaloneClean$ShuckedWeight / (abaloneClean$Length * abaloneClean$Height)

abaloneNewFeat$DensityShell = abaloneClean$ShellWeight / (abaloneClean$Diameter^2)

summary (abaloneNewFeat[, (ncol(abaloneNewFeat)-2):ncol(abaloneNewFeat)])

scaledAbalone = stack(as.data.frame(scale(abaloneNewFeat[, (ncol(abaloneNewFeat)-2):ncol(abaloneNewFeat)])))

p =ggplot(scaledAbalone) + geom_boxplot(aes(x = ind, y = values, color=ind)) + guides(colour=FALSE)

p + theme(axis.title.x = element_blank()) + ylab("Nuevas variables de densidad")
```
## Género
 En los siguientes pairplots observamos que no parece grandes diferencias entre las dstribuciones de las variables para hembras y machos. Sin embargo el nivel I sí parece engendrar distribuciones muy diferentes. Por lo tanto vamos a sustituir la variable género por Infancia
```{r}
abaloneNewFeat$Infancy = combineLevels(abaloneNewFeat$Sex,levs = c("F", "M"), newLabel = c("A") )
abaloneNewFeat = subset(abaloneNewFeat, select=-c(Sex))

abaloneClean$Infancy = abaloneNewFeat$Infancy
abaloneClean = subset(abaloneClean, select=-c(Sex))
```

```{r}

ggpairs(abaloneNewFeat[,-1:-7], aes(colour = Infancy, alpha = 0.3), title="Pairs plot for abalone dataset",
        upper = list(continuous = wrap("cor", size = 2)), lower = list(combo = wrap("facethist", binwidth = 0.8))) +
  theme_grey(base_size = 8)
```


# Árboles de decisión para regresión
## Conjunto de test y de entrenamiento
```{r}
# Muestro estratificado del conjunto de datos en entrenamiento y test en la proporción 2:1 
train = createDataPartition(abaloneClean$Age, p = 2/3, list = FALSE)
#train = sample(1:nrow(abaloneClean), nrow(abaloneClean)*0.7)
Ntrain = length(train)
test = (-train)
Ntest = nrow(abaloneClean) - Ntrain

# Eliminamos la variable Rings porque es redundante con Age
abaloneNewFeat = subset(abaloneNewFeat, select=-c(Rings))
```

### Arboles de decisión, Random Forest y boosting
Aunque los árboles de decisión son fáciles de interpretar, suelen ser muy sensibles al conjunto de entrenamiento. Técnicas como bagging o boosting producen modelos más robustos pero de interpretación más complicada.
Sin embargo, suponen una excelente manera de identificar las variables que mayor influencia ejercen sobre la salida.

```{r}

formulaTrees = Age ~ .

tree.mod = tree(formulaTrees, data = abaloneNewFeat[train,])

summary(tree.mod)

plot(tree.mod)
text(tree.mod, pretty=0)

cv.mod = cv.tree(tree.mod)
plot(cv.mod$size, cv.mod$dev, type = 'b')

results = calculateResults(predict(tree.mod, newdata = abaloneNewFeat), abaloneNewFeat$Age, train, test, "Arbol simple")


```

```{r}
rf.mod = randomForest(formulaTrees, data = abaloneNewFeat[train,], importance=TRUE)

results = rbind(results,
                calculateResults(predict(rf.mod, newdata = abaloneNewFeat), abaloneNewFeat$Age, train, test, "Random Forest"))


importance(rf.mod)
```

```{r}
boost.mod = gbm(formulaTrees , data = abaloneNewFeat[train,], distribution="gaussian", interaction.depth = 4, n.trees = 9000, shrinkage = 0.005, cv.folds = 5, n.cores = 4)

predictBoostNTrees = gbm.perf(boost.mod)
results = rbind(results, calculateResults(predict(boost.mod, newdata = abaloneNewFeat, n.trees = predictBoostNTrees), abaloneNewFeat$Age, train, test, "Boosting"))

```

```{r}
results = rbind(results, calculateResults(predict(boost.mod, newdata = abaloneNewFeat, n.trees = predictBoostNTrees), abaloneNewFeat$Age, train, test, "Boosting"))

showResults(results)
```

Vemos que las variables más influyentes indpendientemente de la técnica utilizada están particularmente relacionadas con la concha: DensityShell, ShellWeight y en tercer lugar DensityShucked. Por ello, deberemos centrarnos en estas variables a la hora de diseñar los modelos de regresión lineal.

# Modelos de regresión

## Regresión múltiple

En primer lugar empezaremos con las variables inicialmente disponibles, para luego extender el modelo a las nuevas variables.

### Variables iniciales
```{r}

lm.fit = lm(Age ~. - Rings, data = abaloneClean[train,])
summary(lm.fit)
```
Eliminamos las variables no significativas (con grandes p-valores (>0.01)):

```{r}
formula = Age ~. - Length - Rings
lm.fit = lm(formula , data=abaloneClean[train,])
summary(lm.fit)

results = rbind(results,
calculateResults(predict(lm.fit, abaloneClean), abaloneClean$Age, train, test, "Variables iniciales", length(lm.fit$coefficients) - 1))

plotModel(lm.fit)


```
#### Corrección de la heterocedasticidad
Observamos como los errores no son normales. Por el contrario, como ya apuntamos en el [análisis exploratorio](./AnalisisExploratorio.html), la desviación parece aumentar con el valor de la variable dependiente y es asimétrica, con una cola más larga a la derecha. Como sospechábamos, los residuos no son homocedásticos. Veamos el resultado de transformar los pesos y de transformar la variable dependiente.

```{r}
wts <- 1/fitted(lm(abs(residuals(lm.fit)) ~ fitted(lm.fit)))^2
wlm.fit = lm(formula, data=abaloneClean[train,], weights = wts)
summary(wlm.fit)
plotModel(wlm.fit)

results = rbind(results, calculateResults(predict(wlm.fit, abaloneClean), abaloneClean$Age, train, test, "Local weights", length(wlm.fit$coefficients) - 1))
```

```{r}
formula = Rings ~. - Age - Length
lnlm.fit = glm(formula, data=abaloneClean[train,], family = poisson(log))
summary(lnlm.fit)

results = rbind(results, calculateResults(predict.glm(lnlm.fit, abaloneClean, type = "response"), abaloneClean$Rings, train, test, "log linear", length(lnlm.fit$coefficients) - 1))
showResults(results)
plotModel(lnlm.fit)

sqrtlm.fit = glm(formula, data=abaloneClean[train,], family = poisson(sqrt))
summary(lnlm.fit)

results = rbind(results, calculateResults(predict.glm(sqrtlm.fit, abaloneClean, type = "response"), abaloneClean$Rings, train, test, "sqrt linear", length(sqrtlm.fit$coefficients) - 1))
plotModel(sqrtlm.fit)
```



### Nuevas variables

```{r}
lm.fit = lm(Age ~ Infancy*(1 + Height + log(WholeWeight) + log(ShuckedWeight) + log(VisceraWeight) + log(ShellWeight)), data=abaloneNewFeat[train,])
summary(lm.fit)
results = rbind(results, calculateResults(predict(lm.fit, abaloneNewFeat), abaloneNewFeat$Age, train, test, "Lineal Log", length(lm.fit$coefficients) - 1))


lm.fit = lm(Age ~ Infancy*(1 + Height + log(WholeWeight) + log(ShuckedWeight) + log(VisceraWeight) + log(ShellWeight) + log(WeightNorm) + Volume + SizeGeoNorm + SizeGeoMean + DensityShell + DensityShucked + Density), data=abaloneNewFeat[train,])
summary(lm.fit)
results = rbind(results, calculateResults(predict(lm.fit, abaloneNewFeat), abaloneNewFeat$Age, train, test, "Nuevas variables", length(lm.fit$coefficients) - 1))

lm.fit = lm(Age ~ Infancy*(1 + log(ShuckedWeight) + log(VisceraWeight) + log(WeightNorm) + Volume), data=abaloneNewFeat[train,])
summary(lm.fit)
results = rbind(results, calculateResults(predict(lm.fit, abaloneNewFeat), abaloneNewFeat$Age, train, test, "Subconjunto nuevas variables", length(lm.fit$coefficients) - 1))


plotModel(lm.fit)

```



## Reduccion de dimensionalidad y colinealidad
Tratemos ahora de resolver el problema de colinealidad entre las variables.

### Generar todas las variables de interés
```{r}
abaloneNewFeat$LogWhole = log(abaloneNewFeat$WholeWeight)
abaloneNewFeat$LogShucked = log(abaloneNewFeat$ShuckedWeight)
abaloneNewFeat$LogViscera = log(abaloneNewFeat$VisceraWeight)
abaloneNewFeat$LogShell = log(abaloneNewFeat$ShellWeight)

abaloneNewFeat$Expole = exp(I(-abaloneNewFeat$WholeWeight))
abaloneNewFeat$ExpShucked = exp(-abaloneNewFeat$ShuckedWeight)
abaloneNewFeat$ExpViscera = exp(-abaloneNewFeat$VisceraWeight)
abaloneNewFeat$ExpShell = exp(-abaloneNewFeat$ShellWeight)
```


### Método de Lasso
Vamos a elegir el valor del parámetro $\alpha$ del método de Lasso que minimice el error cuadrático por validación cruzada.
```{r}
# Generación de los valores de lambda y separacion de la matrix de entradas y el vector de salida

grid = 10^seq(5,-6, length=100)
x = model.matrix(Age~.^2 , abaloneNewFeat)
y = abaloneNewFeat$Age
```

```{r}
# Generación del modelo de Lasso
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid)
plot(lasso.mod)
```

```{r}
# Obtención del valor de lambda que minimiza el ECM por validación cruzada con n=10
cv.out = cv.glmnet(x[train,], y[train], alpha=1, lambda=grid, nfolds=10)
plot(cv.out)

# Elegimos lambda que minimiza el ECM
bestLambda = cv.out$lambda.1se
coef(lasso.mod,s=bestLambda)

# Cálculo del ECM de entrenamiento y de test
Dvar = cv.out$nzero[cv.out$lambda == bestLambda]

results = rbind(results, calculateResults(predict(lasso.mod,s=bestLambda,newx=x), y, train, test, "Lasso", Dvar))
```
### Método de Ridge

```{r}
# Generación del modelo de red elástica
ridge.mod = glmnet(x[train,], y[train], alpha=0, lambda=grid)
plot(ridge.mod)
```

```{r}
# Obtención del valor de lambda que minimiza el error cuadrático medio por validación cruzada con n=10
cv.out = cv.glmnet(x[train,], y[train], alpha=0, lambda=grid, nfolds=10)
plot(cv.out)

# Elegimos lambda que minimiza el error cuadratico medio dentro de una desviacion estandar
bestLambda = cv.out$lambda.1se
coef(ridge.mod,s=bestLambda)


# Cálculo del Error cuadrático medio del modelo en el conjunto de entrenamiento y de test
Dvar = cv.out$nzero[cv.out$lambda == bestLambda]

results = rbind(results, calculateResults(predict(ridge.mod,s=bestLambda,newx=x), y, train, test, "Ridge", Dvar))

```
### Método Elastic Net

```{r}
# Generación del modelo de red elástica
cv_10 = trainControl(method = "cv", number = 10, selectionFunction = "oneSE")

cv.elnet = train(
  Age ~ .^2, data = abaloneNewFeat[train,],
  method = "glmnet",
  trControl = cv_10,
  tuneLength = 20
)


elnet.mod = glmnet(x[train,], y[train], alpha=cv.elnet$bestTune$alpha, lambda=cv.elnet$bestTune$lambda)



Dvar = sum(coef(cv.elnet$finalModel, cv.elnet$finalModel$lambdaOpt)==0)
results = rbind(results, calculateResults(predict(elnet.mod,s=bestLambda,newx=x), y, train, test, "Elastic Net", Dvar))

showResults(results)

```





